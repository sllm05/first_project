import random
import os
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime

# PDF ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
# ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install reportlab
from reportlab.pdfgen import canvas
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from reportlab.lib.pagesizes import letter

class EmotionBasedPsychotherapy:
    # --- __init__ (ìƒì„±ì) ìˆ˜ì • ---
    def __init__(self, client, emotion_df, md_retriever):
        self.client = client
        self.emotion_df = emotion_df  # ê°ì„±ëŒ€í™” ë°ì´í„° ì¶”ê°€
        self.md_retriever = md_retriever  # Markdown Retriever ì¶”ê°€
        self.score = 0
        self.question_index = 0
        self.chat_history = [] # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

        self.all_questions = [
            "ìµœê·¼ 2ì£¼ ë™ì•ˆ, ì¼ìƒì ì¸ ì¼ì— ëŒ€í•œ í¥ë¯¸ë‚˜ ì¦ê±°ì›€ì´ ê±°ì˜ ì—†ì—ˆë‹¤.",
            "ê¸°ë¶„ì´ ê°€ë¼ì•‰ê±°ë‚˜ ìš°ìš¸í•˜ê±°ë‚˜ ì ˆë§ê°ì„ ëŠê¼ˆë‹¤.",
            "ì ë“¤ê¸° ì–´ë µê±°ë‚˜, ìì£¼ ê¹¼ê±°ë‚˜, í˜¹ì€ ë„ˆë¬´ ë§ì´ ì ì„ ì¤ë‹¤.",
            "í”¼ê³¤í•˜ê±°ë‚˜ ê¸°ìš´ì´ ì—†ì—ˆë‹¤.",
            "ì‹ìš•ì´ ì¤„ì—ˆê±°ë‚˜ ì§€ë‚˜ì¹˜ê²Œ ë¨¹ì—ˆë‹¤.",
            "ìì‹ ì´ ì‹¤íŒ¨ìë¼ê³  ëŠë¼ê±°ë‚˜ ìì‹ ì´ë‚˜ ê°€ì¡±ì„ ì‹¤ë§ì‹œì¼°ë‹¤ê³  ëŠê¼ˆë‹¤.",
            "ì‹ ë¬¸ì„ ì½ê±°ë‚˜ TVë¥¼ ë³´ëŠ” ê²ƒì²˜ëŸ¼ ì§‘ì¤‘í•˜ê¸°ê°€ ì–´ë ¤ì› ë‹¤.",
            "ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì•Œì•„ì°¨ë¦´ ì •ë„ë¡œ ë„ˆë¬´ ëŠë¦¬ê²Œ ì›€ì§ì˜€ê±°ë‚˜, ë„ˆë¬´ ì•ˆì ˆë¶€ì ˆ ëª»í•˜ê²Œ ì›€ì§ì˜€ë‹¤.",
            "ìì‹ ì„ í•´ì¹˜ê±°ë‚˜ ì£½ì´ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì„ í–ˆë‹¤."
        ]
        self.screening_questions = random.sample(self.all_questions, 5)
        self.total_questions = len(self.screening_questions)

        self.emotion_levels = {
            'ìœ„í—˜': ['ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìŠ¬í””'],
            'ë³´í†µ': ['ë‹¹í™©', 'ìƒì²˜'],
            'ì •ìƒ': ['ê¸°ì¨']
        }
        self.emotion_scores = {'ìœ„í—˜': 3, 'ë³´í†µ': 1, 'ì •ìƒ': 0}

        # --- ê¸°ì¡´ RAG ì²´ì¸ ì‚­ì œ, ì •ë³´ ê²€ìƒ‰ ì²´ì¸ìœ¼ë¡œ ëŒ€ì²´ ---
        qa_system_prompt = """ë‹¹ì‹ ì€ ìš°ìš¸ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì„¸ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.
        {context}"""
        qa_prompt = ChatPromptTemplate.from_messages([("system", qa_system_prompt), ("human", "{input}")])
        Youtube_chain = create_stuff_documents_chain(ChatUpstage(model="solar-1-mini"), qa_prompt)
        self.rag_chain = create_retrieval_chain(self.md_retriever, Youtube_chain)

    def get_emotion_level(self, emotion):
        for level, emotions in self.emotion_levels.items():
            if emotion in emotions:
                return level
        return 'ë³´í†µ'

    def _call_solar_for_emotion(self, text):
        emotion_categories = ['ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìŠ¬í””', 'ìƒì²˜', 'ë‹¹í™©', 'ê¸°ì¨']
        prompt_messages = [
            {"role": "system", "content": f"ë„ˆëŠ” ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ {emotion_categories} ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ë§ˆ."},
            {"role": "user", "content": text}
        ]
        try:
            response = self.client.chat.completions.create(model="solar-mini", messages=prompt_messages, temperature=0.0, max_tokens=10)
            content = response.choices[0].message.content.strip()
            return content if content in emotion_categories else 'ìƒì²˜'
        except Exception as e:
            print(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return 'ìƒì²˜'

    # --- generate_empathetic_response_and_ask_question ìˆ˜ì • ---
    def generate_empathetic_response_and_ask_question(self, user_input):
        if self.is_test_finished():
            return None

        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.chat_history.append({"role": "user", "content": user_input})

        next_question = self.screening_questions[self.question_index]

        # ê°ì„±ëŒ€í™” ë§ë­‰ì¹˜ì—ì„œ ì˜ˆì‹œ ì¶”ì¶œ (Few-shot Prompting)
        samples = self.emotion_df.sample(n=2)
        few_shot_examples = ""
        for index, row in samples.iterrows():
            few_shot_examples += f"\n#ëŒ€í™” ì˜ˆì‹œ {index+1}\n- ì‚¬ìš©ì: {row['ì‚¬ëŒë¬¸ì¥1']}\n- ìƒë‹´ì‚¬: {row['ì‹œìŠ¤í…œë¬¸ì¥1']}"

        system_prompt = f"""ë„ˆëŠ” ë”°ëœ»í•œ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì´ë‹¤. ì•„ë˜ ëŒ€í™” ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ì‚¬ìš©ìì˜ ë§ì— ìì—°ìŠ¤ëŸ½ê²Œ ê³µê°í•œ í›„, ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°„ë‹¤.

{few_shot_examples}

# ì§€ì‹œì‚¬í•­
1. ì‚¬ìš©ìì˜ ë§ì— ì ê·¹ì ìœ¼ë¡œ ê³µê°í•œë‹¤.
2. ê·¸ ë‹¤ìŒ, ì•„ë˜ ì „ë‹¬ëœ 'ì˜¤ëŠ˜ì˜ ì§ˆë¬¸'ì„ ì´ì–´ì„œ ë¬¼ì–´ë³¸ë‹¤.
3. ë‘ ë¬¸ì¥ì„ í•©ì³ì„œ ë¶€ë“œëŸ¬ìš´ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë§Œë“ ë‹¤. "ì˜¤ëŠ˜ì˜ ì§ˆë¬¸:" ê°™ì€ ì œëª©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.

# ì˜¤ëŠ˜ì˜ ì§ˆë¬¸
{next_question}
"""
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]

        response = self.client.chat.completions.create(model="solar-pro", messages=messages, temperature=0.7)
        bot_response = response.choices[0].message.content

        # ì±—ë´‡ì˜ ë‹µë³€ë„ ëŒ€í™” ê¸°ë¡ì— ì €ì¥
        self.chat_history.append({"role": "assistant", "content": bot_response})

        return bot_response

    def process_and_score_answer(self, answer):
        emotion = self._call_solar_for_emotion(answer)
        level = self.get_emotion_level(emotion)
        points = self.emotion_scores.get(level, 0)
        self.score += points
        self.question_index += 1
        return f"ê°ì •: {emotion}({level}), {points}ì  ì¶”ê°€ (í˜„ì¬ ì´ì : {self.score}ì )"

    def is_test_finished(self):
        return self.question_index >= self.total_questions

    def display_final_result(self):
        result_text = f"ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ì´ì : {self.score}ì **\n\n"
        if self.score >= 10:
            result_text += "ğŸš¨ **ì§„ë‹¨ ê²°ê³¼: ìš°ìš¸ì¦ ìœ„í—˜** ğŸš¨\në†’ì€ ìˆ˜ì¤€ì˜ ìš°ìš¸ê°ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. ì „ë¬¸ê°€ì˜ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        elif self.score >= 5:
            result_text += "ğŸ’› **ì§„ë‹¨ ê²°ê³¼: ë³´í†µ** ğŸ’›\nì¼ìƒì ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ë‚˜ ê°€ë²¼ìš´ ìš°ìš¸ê°ì„ ê²ªê³  ê³„ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤."
        else:
            result_text += "ğŸ˜„ **ì§„ë‹¨ ê²°ê³¼: ì •ìƒ** ğŸ˜„\n"
        return result_text

    # --- ê¸°ì¡´ RAG í•¨ìˆ˜ë“¤ì„ ëŒ€ì²´í•  ìƒˆë¡œìš´ í•¨ìˆ˜ë“¤ ---

    def get_info_from_md(self, user_input):
        """depression.md íŒŒì¼ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€í•˜ëŠ” í•¨ìˆ˜"""
        if not self.rag_chain:
            return "ì •ë³´ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        result = self.rag_chain.invoke({"input": user_input})
        return result["answer"]

    # --- summarize_for_report ìˆ˜ì • ---
    def summarize_for_report(self, uploaded_pdf_text=None):
        """ëŒ€í™” ë‚´ìš©ê³¼ ì—…ë¡œë“œëœ PDFë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³´ê³ ì„œ ë‚´ìš©ì„ ìš”ì•½/ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""

        conversation_text = "\n".join([f"{msg['role']}: {msg['content']}" for msg in self.chat_history])

        # ì°¸ê³  ìë£Œ ì„¹ì…˜ êµ¬ì„±
        reference_material = f"--- ëŒ€í™” ë‚´ìš© ---\n{conversation_text}"
        if uploaded_pdf_text:
            reference_material += f"\n\n--- ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ ì°¸ê³  ë¬¸ì„œ ë‚´ìš© ---\n{uploaded_pdf_text}"

        prompt = f"""
        ë‹¹ì‹ ì€ ì •ì‹ ê³¼ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. ì•„ë˜ ì°¸ê³  ìë£Œ(ëŒ€í™” ë‚´ìš©, ì‚¬ìš©ì ì œì¶œ ë¬¸ì„œ)ë¥¼ ì¢…í•©ì ìœ¼ë¡œ ê²€í† í•˜ì—¬ 'ìš°ìš¸ì¦ ìê°€ ì§„ë‹¨ì„œ'ì˜ ê° í•­ëª©ì„ ì±„ì›Œì£¼ì„¸ìš”.
        ê²°ê³¼ëŠ” ê° í•­ëª©ì— ëŒ€í•œ ì„¤ëª…ë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ê³ , ë‹¤ë¥¸ ë§ì€ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
        ê° í•­ëª©ì€ "í•­ëª©ëª…: ë‚´ìš©" í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

        - í™˜ì ì •ë³´: (ì˜ˆ: íŠ¹ì • ì •ë³´ ì—†ìŒ, ì˜¨ë¼ì¸ ì‚¬ìš©ì)
        - ì£¼ëœ ì¦ìƒ: (ì˜ˆ: ë¶ˆë©´, ë¶ˆì•ˆ, ìš°ìš¸ê° ë“± ëŒ€í™”ì—ì„œ ë‚˜íƒ€ë‚œ í•µì‹¬ ì¦ìƒ ìš”ì•½)
        - ì§„ë‹¨ëª…(ì¶”ì •): (ì˜ˆ: ìš°ìš¸ì¦ ì˜ì‹¬, ìŠ¤íŠ¸ë ˆìŠ¤ ë°˜ì‘ ë“±)
        - ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­): (ì˜ˆ: ì „ë¬¸ê°€ ìƒë‹´ ê¶Œìœ , ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë¦¬ í•„ìš” ë“±)

        {reference_material}
        """

        response = self.client.chat.completions.create(
            model="solar-pro",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3
        )

        summary_text = response.choices[0].message.content
        report_data = {}
        for line in summary_text.split('\n'):
            if ':' in line:
                key, value = line.split(':', 1)
                report_data[key.strip()] = value.strip()

        return report_data

    def create_report_pdf(self, report_data, output_path):
        """ë¶„ì„ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
        try:
            # ìœˆë„ìš° í™˜ê²½ì— ë§ëŠ” ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ. ë‹¤ë¥¸ í™˜ê²½ì—ì„œëŠ” ê²½ë¡œ ìˆ˜ì • í•„ìš”.
            # í°íŠ¸ íŒŒì¼ì´ ì—†ë‹¤ë©´ ë³„ë„ ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
            font_path = "font/NanumGothic.ttf"
            pdfmetrics.registerFont(TTFont('NanumGothic', font_path))
        except Exception as e:
            print(f"í°íŠ¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}. ê¸°ë³¸ í°íŠ¸ë¡œ ìƒì„±ë©ë‹ˆë‹¤.")
            # í°íŠ¸ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬ë„ ê°€ëŠ¥

        c = canvas.Canvas(output_path, pagesize=letter)
        width, height = letter

        # ì œëª©
        c.setFont('NanumGothic', 18)
        c.drawCentredString(width / 2.0, height - 50, "ìš°ìš¸ì¦ ìê°€ ì§„ë‹¨ ê²°ê³¼ì„œ")

        # ë‚´ìš©
        c.setFont('NanumGothic', 12)
        text_y = height - 100

        # ê¸°ë³¸ ì •ë³´ ì¶”ê°€
        report_data['ì§„ë‹¨ì¼ì'] = datetime.now().strftime("%Y-%m-%d")
        report_data['ì´ì '] = f"{self.score} ì "

        # ë°ì´í„° ìˆœì„œ ì •ì˜
        display_order = ['ì§„ë‹¨ì¼ì', 'í™˜ì ì •ë³´', 'ì´ì ', 'ì£¼ëœ ì¦ìƒ', 'ì§„ë‹¨ëª…(ì¶”ì •)', 'ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)']

        for key in display_order:
            value = report_data.get(key, "ë‚´ìš© ì—†ìŒ")
            c.drawString(100, text_y, f"â–  {key}: {value}")
            text_y -= 30 # ì¤„ ê°„ê²©

        c.save()
        return True