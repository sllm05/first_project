import random
import os
import json
from langchain_core.messages import HumanMessage, SystemMessage
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime

# PDF ìƒì„±ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
# ì„¤ì¹˜ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install reportlab
from reportlab.pdfgen import canvas
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from reportlab.lib.pagesizes import letter
from reportlab.platypus import Paragraph
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_LEFT
from reportlab.lib.colors import black

class EmotionBasedPsychotherapy:
    # --- __init__ (ìƒì„±ì) ìˆ˜ì • ---
    def __init__(self, emotion_df, md_retriever):
        self.emotion_df = emotion_df  # ê°ì„±ëŒ€í™” ë°ì´í„° ì¶”ê°€
        self.md_retriever = md_retriever  # Markdown Retriever ì¶”ê°€
        self.score = 0
        self.question_index = 0
        self.chat_history = [] # ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸

            # --- ëª¨ë“  LLM í˜¸ì¶œì„ ë‹´ë‹¹í•  ChatUpstage ê°ì²´ ìƒì„± ---
        self.llm = ChatUpstage(model="solar-mini")

        self.all_questions = [
            "ì¼ìƒì ì¸ í™œë™ì— ëŒ€í•œ í¥ë¯¸ë‚˜ ì¦ê±°ì›€ì´ ë§ì´ ì¤„ì–´ë“¤ì—ˆë‚˜ìš”?",
            "ê¸°ë¶„ì´ ê°€ë¼ì•‰ê±°ë‚˜ ìš°ìš¸í•˜ê³  ì ˆë§ì ì¸ ëŠë‚Œì´ ë“¤ì—ˆë‚˜ìš”?",
            "ì ë“¤ê¸° ì–´ë µê±°ë‚˜ ìì£¼ ê¹¨ëŠ” ë“± ìˆ˜ë©´ì— ë¬¸ì œê°€ ìˆì—ˆë‚˜ìš”?",
            "í‰ì†Œë³´ë‹¤ í”¼ê³¤í•˜ê³  ê¸°ìš´ì´ ì—†ëŠ” ëŠë‚Œì„ ìì£¼ ë°›ì•˜ë‚˜ìš”?",
            "ì‹ìš•ì´ í¬ê²Œ ì¤„ê±°ë‚˜ ë°˜ëŒ€ë¡œ ë„ˆë¬´ ë§ì´ ë¨¹ì§€ëŠ” ì•Šì•˜ë‚˜ìš”?",
            "ìŠ¤ìŠ¤ë¡œë¥¼ ì‹¤íŒ¨ìë¼ê³  ëŠë¼ê±°ë‚˜ ê°€ì¡±ì„ ì‹¤ë§ì‹œì¼°ë‹¤ëŠ” ì£„ì±…ê°ì´ ë“¤ì—ˆë‚˜ìš”?",
            "ì‹ ë¬¸ì´ë‚˜ TVë¥¼ ë³´ëŠ” ê²ƒê³¼ ê°™ì€ ì¼ìƒì ì¸ ì¼ì— ì§‘ì¤‘í•˜ê¸° ì–´ë ¤ì› ë‚˜ìš”?",
            "ë‹¤ë¥¸ ì‚¬ëŒì´ ì•Œì•„ì±Œ ì •ë„ë¡œ í–‰ë™ì´ êµ¼ë– ì§€ê±°ë‚˜, í˜¹ì€ ë„ˆë¬´ ì•ˆì ˆë¶€ì ˆëª»í•˜ì§€ëŠ” ì•Šì•˜ë‚˜ìš”?",
            "ì°¨ë¼ë¦¬ ì£½ëŠ” ê²Œ ë‚«ê² ë‹¤ê±°ë‚˜ ìŠ¤ìŠ¤ë¡œë¥¼ í•´ì¹˜ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì„ í•œ ì ì´ ìˆë‚˜ìš”?"
        ]
        self.screening_questions = random.sample(self.all_questions, 5)
        self.total_questions = len(self.screening_questions)

        self.emotion_levels = {
            'ìœ„í—˜': ['ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìŠ¬í””'],
            'ë³´í†µ': ['ë‹¹í™©', 'ìƒì²˜'],
            'ì •ìƒ': ['ê¸°ì¨']
        }
        self.emotion_scores = {'ìœ„í—˜': 3, 'ë³´í†µ': 1, 'ì •ìƒ': 0}

        # --- ê¸°ì¡´ RAG ì²´ì¸ ì‚­ì œ, ì •ë³´ ê²€ìƒ‰ ì²´ì¸ìœ¼ë¡œ ëŒ€ì²´ ---
        qa_system_prompt = """ë‹¹ì‹ ì€ ìš°ìš¸ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ë‹µë³€ì€ í•œêµ­ì–´ë¡œ, ì„¸ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.
        {context}"""
        qa_prompt = ChatPromptTemplate.from_messages([("system", qa_system_prompt), ("human", "{input}")])
        Youtube_chain = create_stuff_documents_chain(self.llm, qa_prompt)
        self.rag_chain = create_retrieval_chain(self.md_retriever, Youtube_chain)

    def generate_final_analysis(self, user_data):
        # 1. ì¢…í•©ì ì¸ ì •ë³´ ìš”ì•½
        user_summary = f"""
        - ì‚¬ìš©ì: {user_data.get('ë‚˜ì´')}ì„¸ {user_data.get('ì„±ë³„')}, ì´ë¦„: {user_data.get('ì´ë¦„')}
        - ê³¼ê±° ë³‘ë ¥: {user_data.get('ê³¼ê±° ë³‘ë ¥', 'ì—†ìŒ')}
        - ì£¼ìš” ì¦ìƒ: {user_data.get('ì£¼ìš” ì¦ìƒ')}
        - 5ê°€ì§€ ì§ˆë¬¸ í‰ê°€ ì ìˆ˜: {self.score} ì 
        - ì‚¬ìš©ìì˜ ì„œìˆ : {user_data.get('ì„œìˆ í˜• ë‹µë³€')}
        """

        # 2. ìš”ì•½ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ RAG ì‹œìŠ¤í…œì— ë˜ì§ˆ í•µì‹¬ ì§ˆë¬¸ ìƒì„±
        # ì´ ë‹¨ê³„ëŠ” LLMì„ í•œë²ˆ ë” ì¨ì„œ ë§Œë“¤ ìˆ˜ë„ ìˆì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ í…œí”Œë¦¿ ì‚¬ìš©
        main_query = f"{user_data.get('ì£¼ìš” ì¦ìƒ')}ê³¼ {user_data.get('ì„œìˆ í˜• ë‹µë³€')} ë‚´ìš©ì„ ê²ªëŠ” {user_data.get('ë‚˜ì´')}ì„¸ ì‚¬ìš©ìë¥¼ ìœ„í•œ ìš°ìš¸ì¦ ê´€ë¦¬ ë°©ë²•, ì›ì¸, ì¹˜ë£Œë²•, ì§€ì› ì²´ê³„ë¥¼ ì•Œë ¤ì¤˜."

        # 3. RAGë¡œ depression.mdì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰
        rag_context = self.rag_chain.invoke({"input": main_query})
        retrieved_info = "\n".join([doc.page_content for doc in rag_context['context']])

        # 4. ìµœì¢… ë‹µë³€ ìƒì„±
        final_prompt = f"""
        ë‹¹ì‹ ì€ ë§¤ìš° ê³µê° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ì‹¬ë¦¬ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ì‚¬ìš©ì ì •ë³´ì™€ ì „ë¬¸ê°€ì˜ ë¶„ì„ ë…¸íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•  ìµœì¢… ë‹µë³€ì„ ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ### ì‚¬ìš©ì ì •ë³´
        {user_summary}

        ### ì „ë¬¸ê°€ ë¶„ì„ ë…¸íŠ¸ (ê²€ìƒ‰ëœ ì •ë³´)
        {retrieved_info}

        ### ì§€ì‹œì‚¬í•­
        1. **(ì§€ì› ì²´ê³„)**: ë¶„ì„ ë…¸íŠ¸ë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì—ê²Œ ë„ì›€ì´ ë  ë§Œí•œ ê¸°ê´€ì´ë‚˜ ì§€ì› í”„ë¡œê·¸ë¨ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.
        2. **(ê´€ë¦¬ ë°©ë²•)**: ì‚¬ìš©ìê°€ ì¼ìƒì—ì„œ ì‹œë„í•´ë³¼ ìˆ˜ ìˆëŠ” í˜„ì‹¤ì ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ ë° ìš°ìš¸ê° ê´€ë¦¬ ë°©ë²•ì„ 2-3ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
        3. **(ì›ì¸ ë° ì¹˜ë£Œë²•)**: ì‚¬ìš©ìì˜ ì¦ìƒê³¼ ê´€ë ¨ëœ ì›ì¸ì„ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ê³ , ì¼ë°˜ì ì¸ ì¹˜ë£Œ ë°©ë²•ì— ëŒ€í•´ í¬ë§ì ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
        4. **(ê¸ì •ì ì´ê³  ë”°ëœ»í•œ ë§ˆë¬´ë¦¬)**: ëª¨ë“  ë‚´ìš©ì„ ì¢…í•©í•˜ì—¬, ì‚¬ìš©ìì˜ ë…¸ë ¥ì„ ì¸ì •í•˜ê³  í¬ë§ì„ ì£¼ëŠ” ë§¤ìš° ë”°ëœ»í•˜ê³  ì§„ì‹¬ ì–´ë¦° ì‘ì› ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”. (ì œëª©ì„ ì§„ì‹¬ ì–´ë¦° ì‘ì› ë©”ì‹œì§€ê°€ ì•„ë‹ˆê³  ë‹¤ë¥¸ ì¢‹ì€ ë§ì„ ì°¾ì•„ë´)

        ìœ„ 4ê°€ì§€ í•­ëª©ì„ ê°ê° ì†Œì œëª©ìœ¼ë¡œ êµ¬ë¶„í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """

        response = self.llm.invoke([HumanMessage(content=final_prompt)], model="solar-pro", temperature=0.7)

        return response.content


    def get_emotion_level(self, emotion):
        for level, emotions in self.emotion_levels.items():
            if emotion in emotions:
                return level
        return 'ë³´í†µ'

    def _call_solar_for_emotion(self, text):
        emotion_categories = ['ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìŠ¬í””', 'ìƒì²˜', 'ë‹¹í™©', 'ê¸°ì¨']
        messages = [
            SystemMessage(content=f"ë„ˆëŠ” ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ {emotion_categories} ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ë§ˆ."),
            HumanMessage(content=text)
        ]
        try:
            response = self.llm.invoke(messages, temperature=0.0, max_tokens=10)
            content = response.content.strip()
            return content if content in emotion_categories else 'ìƒì²˜'
        except Exception as e:
            print(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return 'ìƒì²˜'

    # --- generate_empathetic_response_and_ask_question ìˆ˜ì • ---
    def generate_empathetic_response_and_ask_question(self, user_input):
        if self.is_test_finished():
            return None

        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        self.chat_history.append({"role": "user", "content": user_input})

        next_question = self.screening_questions[self.question_index]

        # ê°ì„±ëŒ€í™” ë§ë­‰ì¹˜ì—ì„œ ì˜ˆì‹œ ì¶”ì¶œ (Few-shot Prompting)
        samples = self.emotion_df.sample(n=2)
        few_shot_examples = ""
        for index, row in samples.iterrows():
            few_shot_examples += f"\n#ëŒ€í™” ì˜ˆì‹œ {index+1}\n- ì‚¬ìš©ì: {row['ì‚¬ëŒë¬¸ì¥1']}\n- ìƒë‹´ì‚¬: {row['ì‹œìŠ¤í…œë¬¸ì¥1']}"

        system_prompt = f"""
            ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ê³µê°ëŠ¥ë ¥ì´ ë›°ì–´ë‚œ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì´ì „ ë‹µë³€ì— ëŒ€í•´ í•œë‘ ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ ê³µê°í•´ì£¼ì„¸ìš”.
            ê·¸ ë‹¤ìŒ, ë‹¤ë¥¸ ë§ì„ ì¶”ê°€í•˜ì§€ ë§ê³  ì•„ë˜ì— ì£¼ì–´ì§„ 'ë‹¤ìŒì— í•  ì§ˆë¬¸'ì„ ê·¸ëŒ€ë¡œ ì´ì–´ì„œ ë¬¼ì–´ë³´ì„¸ìš”.
            'ì˜¤ëŠ˜ì˜ ì§ˆë¬¸' ê°™ì€ ì œëª©ì´ë‚˜ ë‹¤ë¥¸ ì§ˆë¬¸ì„ ì ˆëŒ€ë¡œ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.

            {few_shot_examples}



            ë‹¤ìŒ ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ í•´ì£¼ì„¸ìš”: {next_question}
            """
        messages = [
            SystemMessage(content=system_prompt), 
            HumanMessage(content=user_input)
        ]

        response = self.llm.invoke(messages, temperature=0.7)
        bot_response = response.content

        # ì±—ë´‡ì˜ ë‹µë³€ë„ ëŒ€í™” ê¸°ë¡ì— ì €ì¥
        self.chat_history.append({"role": "assistant", "content": bot_response})

        return bot_response

    def process_and_score_answer(self, answer):
        """LLMì„ ì‚¬ìš©í•´ ì‚¬ìš©ìì˜ ë‹µë³€ì„ ë¶„ì„í•˜ê³  ì ìˆ˜ë¥¼ ë§¤ê¸°ëŠ” ìƒˆë¡œìš´ í•¨ìˆ˜"""
        
        # í˜„ì¬ ì–´ë–¤ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì¸ì§€ ëª…ì‹œ
        current_question = self.screening_questions[self.question_index]
        
        system_prompt = f"""
        ë‹¹ì‹ ì€ ìˆ™ë ¨ëœ ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ë‹µë³€ì„ ì£¼ì–´ì§„ ì§ˆë¬¸ì˜ ë§¥ë½ì—ì„œ ë¶„ì„í•˜ê³ , ìš°ìš¸ê°ì˜ ì‹¬ê°ë„ë¥¼ 0ì ì—ì„œ 3ì  ì‚¬ì´ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.
        - 0ì : ìš°ìš¸ê°ì´ë‚˜ ë¶€ì •ì  ì •ì„œê°€ ì „í˜€ ë“œëŸ¬ë‚˜ì§€ ì•ŠìŒ.
        - 1ì : ì•½ê°„ì˜ ìŠ¤íŠ¸ë ˆìŠ¤ë‚˜ ê°€ë²¼ìš´ ìš°ìš¸ê°ì´ ì•”ì‹œë¨.
        - 2ì : ê½¤ ëª…í™•í•œ ìš°ìš¸ê°, ë¬´ê¸°ë ¥, ë¶ˆì•ˆ ë“±ì´ ë“œëŸ¬ë‚¨.
        - 3ì : ì‹¬ê°í•œ ìˆ˜ì¤€ì˜ ìš°ìš¸ê°, ì ˆë§, ìí•´ ì‚¬ê³  ë“±ì´ ë“œëŸ¬ë‚¨.

        ë°˜ë“œì‹œ ì•„ë˜ì™€ ê°™ì€ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
        {{
        "score": <í‰ê°€ ì ìˆ˜ (0-3)>,
        "reason": "<ì™œ ê·¸ë ‡ê²Œ í‰ê°€í–ˆëŠ”ì§€ì— ëŒ€í•œ ê°„ëµí•œ í•œê¸€ ì„¤ëª…>"
        }}

        ---
        ì§ˆë¬¸: "{current_question}"
        ---
        """
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=f"ì‚¬ìš©ì ë‹µë³€: \"{answer}\"")
        ]

        try:
            response = self.llm.invoke(messages, model="solar-mini", temperature=0.1)
            # LLMì˜ ì‘ë‹µì´ JSON í˜•ì‹ì´ë¯€ë¡œ, ì´ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
            result = json.loads(response.content)
            points = result.get("score", 0)
            reason = result.get("reason", "ë¶„ì„ ì‹¤íŒ¨")
            
            self.score += points
            self.question_index += 1
            
            return f"ë¶„ì„ ê²°ê³¼: {reason} ({points}ì  ì¶”ê°€, í˜„ì¬ ì´ì : {self.score}ì )"

        except Exception as e:
            print(f"ì ìˆ˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            self.question_index += 1
            return f"ì ìˆ˜ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (0ì  ì²˜ë¦¬, í˜„ì¬ ì´ì : {self.score}ì )"

    def is_test_finished(self):
        return self.question_index >= self.total_questions

    def display_final_result(self):
        result_text = f"ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ì´ì : {self.score}ì **\n\n"
        if self.score >= 10:
            result_text += "ğŸš¨ **ì§„ë‹¨ ê²°ê³¼: ìš°ìš¸ì¦ ìœ„í—˜** ğŸš¨\në†’ì€ ìˆ˜ì¤€ì˜ ìš°ìš¸ê°ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. ì „ë¬¸ê°€ì˜ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        elif self.score >= 5:
            result_text += "ğŸ’› **ì§„ë‹¨ ê²°ê³¼: ë³´í†µ** ğŸ’›\nì¼ìƒì ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ë‚˜ ê°€ë²¼ìš´ ìš°ìš¸ê°ì„ ê²ªê³  ê³„ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤."
        else:
            result_text += "ğŸ˜„ **ì§„ë‹¨ ê²°ê³¼: ì •ìƒ** ğŸ˜„\n"
        return result_text

    # --- ê¸°ì¡´ RAG í•¨ìˆ˜ë“¤ì„ ëŒ€ì²´í•  ìƒˆë¡œìš´ í•¨ìˆ˜ë“¤ ---

    def get_info_from_md(self, user_input):
        """depression.md íŒŒì¼ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€í•˜ëŠ” í•¨ìˆ˜"""
        if not self.rag_chain:
            return "ì •ë³´ ê²€ìƒ‰ ê¸°ëŠ¥ì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        result = self.rag_chain.invoke({"input": user_input})
        return result["answer"]
    

    def summarize_for_report(self, user_data, final_score):
        """ì ìˆ˜ ê¸°ë°˜ ì§„ë‹¨ ë¡œì§ê³¼ RAGë¥¼ í™œìš©í•˜ì—¬ ì „ë¬¸ì ì¸ PDF ë³´ê³ ì„œ ë‚´ìš©ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""

        # 1. ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ê¸°ë³¸ ì§„ë‹¨ëª… ê²°ì •
        if final_score >= 12:
            diagnosis_title = "ì¤‘ì¦ ìš°ìš¸ì¦"
        elif 8 <= final_score <= 11:
            diagnosis_title = "ì´ˆê¸° ìš°ìš¸ì¦"
        elif 4 <= final_score <= 7:
            diagnosis_title = "ê°€ë²¼ìš´ ìš°ìš¸ ì¦ìƒ"
        else:  # 3ì  ì´í•˜
            diagnosis_title = "ìš°ìš¸ê° ì—†ìŒ"

        # 2. RAGë¥¼ í†µí•´ ì‚¬ìš©ìì˜ ì¦ìƒê³¼ ê´€ë ¨ëœ ì „ë¬¸ ì •ë³´ ê²€ìƒ‰
        symptoms = user_data.get('ì£¼ìš” ì¦ìƒ', '')
        narrative = user_data.get('ì„œìˆ í˜• ë‹µë³€', '')
        main_query = f"'{diagnosis_title}' ìƒíƒœë¡œ ì§„ë‹¨ë˜ì—ˆê³ , ì£¼ìš” ì¦ìƒì´ '{symptoms}'ì´ë©° '{narrative}'ì™€ ê°™ì€ ì–´ë ¤ì›€ì„ ê²ªëŠ” í™˜ìì— ëŒ€í•œ ì •ë³´"
        
        try:
            retrieved_docs = self.md_retriever.invoke(main_query)
            retrieved_info = "\n".join([doc.page_content for doc in retrieved_docs])
        except Exception as e:
            print(f"RAG ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            retrieved_info = "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

        # 3. ê²€ìƒ‰ëœ ì •ë³´ì™€ ì‚¬ìš©ì ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        final_prompt = f"""
        ë‹¹ì‹ ì€ ì •ì‹ ê±´ê°•ì˜í•™ê³¼ ì „ë¬¸ì˜ì…ë‹ˆë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ 'ìš°ìš¸ì¦ ìê°€ ì§„ë‹¨ ê²°ê³¼ì„œ'ì˜ [ì§„ë‹¨ëª…(ì¶”ì •)]ê³¼ [ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)] í•­ëª©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

        ### í™˜ì ì •ë³´ ###
        - ì´ë¦„: {user_data.get('ì´ë¦„')}
        - ë‚˜ì´/ì„±ë³„: {user_data.get('ë‚˜ì´')}ì„¸ / {user_data.get('ì„±ë³„')}
        - ì´ì : {final_score} ì 
        - ì ìˆ˜ ê¸°ë°˜ ì§„ë‹¨: {diagnosis_title}
        - ì£¼ìš” ì¦ìƒ(ì‚¬ìš©ì ì…ë ¥): {symptoms}
        - ì„œìˆ  ë‚´ìš©(ì‚¬ìš©ì ì…ë ¥): {narrative}
        
        ### ê´€ë ¨ ì˜í•™ ì •ë³´ (depression.md) ###
        {retrieved_info}

        ### ì‘ì„± ì§€ì¹¨ ###
        1. **[ì§„ë‹¨ëª…(ì¶”ì •)]**: ë¨¼ì € ìœ„ 'ì ìˆ˜ ê¸°ë°˜ ì§„ë‹¨'ì¸ '{diagnosis_title}'ì„ ì–¸ê¸‰í•´ì£¼ì„¸ìš”. ê·¸ ë‹¤ìŒ, í™˜ìì˜ ì¦ìƒê³¼ ì˜í•™ ì •ë³´ë¥¼ ì¢…í•©í•˜ì—¬ ì „ë¬¸ì ì¸ ì†Œê²¬ì„ 1~2 ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´í™”í•´ì£¼ì„¸ìš”. (ì˜ˆ: "ì´ˆê¸° ìš°ìš¸ì¦ ìˆ˜ì¤€ìœ¼ë¡œ, íŠ¹íˆ ëŒ€ì¸ê´€ê³„ ìŠ¤íŠ¸ë ˆìŠ¤ì™€ ê´€ë ¨ëœ ë¶ˆì•ˆ ë° ë¬´ê¸°ë ¥ê°ì´ ë‘ë“œëŸ¬ì§‘ë‹ˆë‹¤.")
        2. **[ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)]**: ì‹¤ì œ ì˜ì‚¬ê°€ í™˜ìì—ê²Œ ë§í•˜ë“¯, í˜„ì‹¤ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì¹˜ ë°©ì•ˆì„ ì œì•ˆí•´ì£¼ì„¸ìš”. ì •ì‹ ê±´ê°•ì˜í•™ê³¼ ë°©ë¬¸ ê¶Œìœ , ìƒë‹´ì¹˜ë£Œ, ìƒí™œ ìŠµê´€ ê°œì„  ë“± ë„ì›€ì´ ë  ë§Œí•œ ì •ë³´ë¥¼ ë”°ëœ»í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” ì–´ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ì´ ê° í•­ëª©ì˜ ë‚´ìš©ë§Œ ì‘ì„±í•˜ê³ , ë‹¤ë¥¸ ë§ì€ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
        [ì§„ë‹¨ëª…(ì¶”ì •)]: <ë‚´ìš©>
        [ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)]: <ë‚´ìš©>
        """
        
        messages = [HumanMessage(content=final_prompt)]
        response = self.llm.invoke(messages, model="solar-mini", temperature=0.5)
        report_content = response.content
        report_data = {}
        try:
            diag_part = report_content.split("[ì§„ë‹¨ëª…(ì¶”ì •)]:")[1].split("[ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)]:")[0].strip()
            reco_part = report_content.split("[ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)]:")[1].strip()
            report_data['ì§„ë‹¨ëª…(ì¶”ì •)'] = diag_part
            report_data['ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)'] = reco_part
        except IndexError:
            print("ë³´ê³ ì„œ ë‚´ìš© íŒŒì‹± ì‹¤íŒ¨")
            report_data['ì§„ë‹¨ëª…(ì¶”ì •)'] = "ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            report_data['ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)'] = "ë‚´ìš©ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        report_data['í™˜ì ì •ë³´'] = f"{user_data.get('ì´ë¦„')} ({user_data.get('ë‚˜ì´')}ì„¸, {user_data.get('ì„±ë³„')})"
        report_data['ì£¼ëœ ì¦ìƒ'] = user_data.get('ì£¼ìš” ì¦ìƒ')
        return report_data


    def create_report_pdf(self, report_data, output_path):
        """ë¶„ì„ëœ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìë™ ì¤„ë°”ê¿ˆì´ ì ìš©ëœ PDF ë³´ê³ ì„œë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜"""
        try:
            font_path = "font/NanumGothic.ttf"
            if not os.path.exists(font_path):
                raise FileNotFoundError("í°íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            pdfmetrics.registerFont(TTFont('NanumGothic', font_path))
            font_name = 'NanumGothic'
        except Exception as e:
            print(f"ë‚˜ëˆ”ê³ ë”• í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í°íŠ¸ë¡œ ìƒì„±í•©ë‹ˆë‹¤: {e}")
            font_name = 'Helvetica'

        c = canvas.Canvas(output_path, pagesize=letter)
        width, height = letter

        # --- ìë™ ì¤„ë°”ê¿ˆì„ ìœ„í•œ ìŠ¤íƒ€ì¼ ì •ì˜ ---
        styles = getSampleStyleSheet()
        # ê¸°ë³¸ Paragraph ìŠ¤íƒ€ì¼ì„ ìš°ë¦¬ í°íŠ¸ì— ë§ê²Œ ìƒˆë¡œ ì •ì˜í•©ë‹ˆë‹¤.
        body_style = ParagraphStyle(
            name='Body',
            parent=styles['Normal'],
            fontName=font_name,
            fontSize=12,
            leading=18,  # ì¤„ ê°„ê²©
            alignment=TA_LEFT,
            textColor=black,
        )

        # ì œëª©
        c.setFont(font_name, 18)
        c.drawCentredString(width / 2.0, height - 60, "ìš°ìš¸ì¦ ìê°€ ì§„ë‹¨ ê²°ê³¼ì„œ")

        # --- ë‚´ìš©ì„ Paragraph ê°ì²´ë¡œ ê·¸ë ¤ì£¼ê¸° ---
        text_y = height - 100
        
        # ë³´ê³ ì„œì— í‘œì‹œë  ì •ë³´ì™€ ìˆœì„œ
        report_data['ì§„ë‹¨ì¼ì'] = datetime.now().strftime("%Y-%m-%d")
        report_data['ì´ì '] = f"{self.score} ì "
        display_order = ['ì§„ë‹¨ì¼ì', 'í™˜ì ì •ë³´', 'ì´ì ', 'ì£¼ëœ ì¦ìƒ', 'ì§„ë‹¨ëª…(ì¶”ì •)', 'ì¡°ì¹˜ê²°ê³¼(ê¶Œì¥ì‚¬í•­)']

        for key in display_order:
            value = report_data.get(key, "ë‚´ìš© ì—†ìŒ")
            
            # key ë¶€ë¶„ì€ êµµê²Œ(<b>) ì²˜ë¦¬í•˜ê³ , valueì™€ í•©ì³ì„œ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
            text = f"<b>â–  {key}:</b> {value}"
            
            # Paragraph ê°ì²´ ìƒì„±
            p = Paragraph(text, style=body_style)
            
            # ë¬¸ë‹¨ì´ ê·¸ë ¤ì§ˆ í­ê³¼ ë†’ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. (ì¢Œìš° ì—¬ë°± 100ì”© ì´ 200)
            p_width, p_height = p.wrapOn(c, width - 200, height)
            
            # ê³„ì‚°ëœ ë†’ì´ë§Œí¼ y ìœ„ì¹˜ë¥¼ ì¡°ì •í•œ í›„ ë¬¸ë‹¨ì„ ê·¸ë¦½ë‹ˆë‹¤.
            text_y -= p_height
            p.drawOn(c, 100, text_y)
            
            # í•­ëª© ê°„ì˜ ê°„ê²©ì„ ì¤ë‹ˆë‹¤.
            text_y -= 15

        c.save()
        return True