# ê¸°ëŠ¥
import random
import os
from langchain_upstage import UpstageEmbeddings, ChatUpstage
from langchain_chroma import Chroma
from langchain_community.document_loaders import PyPDFLoader
from langchain.chains import create_history_aware_retriever, create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

class EmotionBasedPsychotherapy:
    def __init__(self, client):
        self.client = client
        self.score = 0
        self.question_index = 0

        self.all_questions = [
            "ìµœê·¼ 2ì£¼ ë™ì•ˆ, ì¼ìƒì ì¸ ì¼ì— ëŒ€í•œ í¥ë¯¸ë‚˜ ì¦ê±°ì›€ì´ ê±°ì˜ ì—†ì—ˆë‹¤.",
            "ê¸°ë¶„ì´ ê°€ë¼ì•‰ê±°ë‚˜ ìš°ìš¸í•˜ê±°ë‚˜ ì ˆë§ê°ì„ ëŠê¼ˆë‹¤.",
            "ì ë“¤ê¸° ì–´ë µê±°ë‚˜, ìì£¼ ê¹¼ê±°ë‚˜, í˜¹ì€ ë„ˆë¬´ ë§ì´ ì ì„ ì¤ë‹¤.",
            "í”¼ê³¤í•˜ê±°ë‚˜ ê¸°ìš´ì´ ì—†ì—ˆë‹¤.",
            "ì‹ìš•ì´ ì¤„ì—ˆê±°ë‚˜ ì§€ë‚˜ì¹˜ê²Œ ë¨¹ì—ˆë‹¤.",
            "ìì‹ ì´ ì‹¤íŒ¨ìë¼ê³  ëŠë¼ê±°ë‚˜ ìì‹ ì´ë‚˜ ê°€ì¡±ì„ ì‹¤ë§ì‹œì¼°ë‹¤ê³  ëŠê¼ˆë‹¤.",
            "ì‹ ë¬¸ì„ ì½ê±°ë‚˜ TVë¥¼ ë³´ëŠ” ê²ƒì²˜ëŸ¼ ì§‘ì¤‘í•˜ê¸°ê°€ ì–´ë ¤ì› ë‹¤.",
            "ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ì•Œì•„ì°¨ë¦´ ì •ë„ë¡œ ë„ˆë¬´ ëŠë¦¬ê²Œ ì›€ì§ì˜€ê±°ë‚˜, ë„ˆë¬´ ì•ˆì ˆë¶€ì ˆ ëª»í•˜ê²Œ ì›€ì§ì˜€ë‹¤.",
            "ìì‹ ì„ í•´ì¹˜ê±°ë‚˜ ì£½ì´ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì„ í–ˆë‹¤."
        ]
        self.screening_questions = random.sample(self.all_questions, 5)
        self.total_questions = len(self.screening_questions)

        self.emotion_levels = {
            'ìœ„í—˜': ['ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìŠ¬í””'],
            'ë³´í†µ': ['ë‹¹í™©', 'ìƒì²˜'],
            'ì •ìƒ': ['ê¸°ì¨']
        }
        self.emotion_scores = {'ìœ„í—˜': 3, 'ë³´í†µ': 1, 'ì •ìƒ': 0}
        self.rag_chain = None

    def get_emotion_level(self, emotion):
        for level, emotions in self.emotion_levels.items():
            if emotion in emotions:
                return level
        return 'ë³´í†µ'

    def _call_solar_for_emotion(self, text):
        emotion_categories = ['ë¶ˆì•ˆ', 'ë¶„ë…¸', 'ìŠ¬í””', 'ìƒì²˜', 'ë‹¹í™©', 'ê¸°ì¨']
        prompt_messages = [
            {
                "role": "system",
                "content": f"ë„ˆëŠ” ë¬¸ì¥ì˜ ê°ì •ì„ ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì•¼. ë‹¤ìŒ ë¬¸ì¥ì˜ ê°ì •ì„ {emotion_categories} ì¤‘ì—ì„œ í•˜ë‚˜ë§Œ ê³¨ë¼. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ë§ˆ."
            },
            {"role": "user", "content": text}
        ]
        try:
            response = self.client.chat.completions.create(
                model="solar-mini", messages=prompt_messages, temperature=0.0, max_tokens=10
            )
            content = response.choices[0].message.content.strip()
            return content if content in emotion_categories else 'ìƒì²˜'
        except Exception as e:
            print(f"API í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            return 'ìƒì²˜'

    def generate_empathetic_response_and_ask_question(self, user_input):
        if self.is_test_finished():
            return None

        next_question = self.screening_questions[self.question_index]
        system_prompt = f"""ë„ˆëŠ” ë”°ëœ»í•œ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì´ë‹¤. ì‚¬ìš©ìì˜ ì´ì „ ë‹µë³€ì— ì§§ê²Œ ê³µê°í•œ í›„, ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€í™”ë¥¼ ì´ëŒì–´ê°„ë‹¤.

# ì§€ì‹œì‚¬í•­
1. ì‚¬ìš©ìì˜ ë§ì— ì ê·¹ì ìœ¼ë¡œ ê³µê°í•œë‹¤.
2. ê·¸ ë‹¤ìŒ, ì•„ë˜ ì „ë‹¬ëœ 'ì˜¤ëŠ˜ì˜ ì§ˆë¬¸'ì„ ì´ì–´ì„œ ë¬¼ì–´ë³¸ë‹¤.
3. ë‘ ë¬¸ì¥ì„ í•©ì³ì„œ ë¶€ë“œëŸ¬ìš´ í•˜ë‚˜ì˜ ë¬¸ë‹¨ìœ¼ë¡œ ë§Œë“ ë‹¤. "ì˜¤ëŠ˜ì˜ ì§ˆë¬¸:" ê°™ì€ ì œëª©ì€ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ì•ŠëŠ”ë‹¤.

# ì˜¤ëŠ˜ì˜ ì§ˆë¬¸
{next_question}
"""
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_input}
        ]
        
        # Streamlitì—ì„œëŠ” ìŠ¤íŠ¸ë¦¬ë° ëŒ€ì‹  í•œë²ˆì— ì‘ë‹µì„ ë°›ì•„ ë°˜í™˜
        response = self.client.chat.completions.create(
            model="solar-pro", messages=messages, temperature=0.7
        )
        return response.choices[0].message.content

    def process_and_score_answer(self, answer):
        emotion = self._call_solar_for_emotion(answer)
        level = self.get_emotion_level(emotion)
        points = self.emotion_scores.get(level, 0)
        self.score += points
        self.question_index += 1
        
        # ë¶„ì„ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë°˜í™˜
        return f"ê°ì •: {emotion}({level}), {points}ì  ì¶”ê°€ (í˜„ì¬ ì´ì : {self.score}ì )"

    def is_test_finished(self):
        return self.question_index >= self.total_questions

    def display_final_result(self):
        result_text = f"ëª¨ë“  ì§ˆë¬¸ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\n\n**ì´ì : {self.score}ì **\n\n"
        if self.score >= 10:
            result_text += "ğŸš¨ **ì§„ë‹¨ ê²°ê³¼: ìš°ìš¸ì¦ ìœ„í—˜** ğŸš¨\në†’ì€ ìˆ˜ì¤€ì˜ ìš°ìš¸ê°ì´ ì˜ì‹¬ë©ë‹ˆë‹¤. ì „ë¬¸ê°€ì˜ ë„ì›€ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        elif self.score >= 5:
            result_text += "ğŸ’› **ì§„ë‹¨ ê²°ê³¼: ë³´í†µ** ğŸ’›\nì¼ìƒì ì¸ ìŠ¤íŠ¸ë ˆìŠ¤ë‚˜ ê°€ë²¼ìš´ ìš°ìš¸ê°ì„ ê²ªê³  ê³„ì‹  ê²ƒ ê°™ìŠµë‹ˆë‹¤."
        else:
            result_text += "ğŸ˜„ **ì§„ë‹¨ ê²°ê³¼: ì •ìƒ** ğŸ˜„\n"
        return result_text
    
    # RAG ì²´ì¸ ì„¤ì • í•¨ìˆ˜ ì¶”ê°€
    def setup_rag_chain(self, file_path):
        loader = PyPDFLoader(file_path)
        pages = loader.load_and_split()
        
        vectorstore = Chroma.from_documents(pages, UpstageEmbeddings(model="solar-embedding-1-large"))
        retriever = vectorstore.as_retriever(k=2)
        
        chat = ChatUpstage(model="solar-1-mini")

        contextualize_q_system_prompt = """ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸ì´ ìˆì„ ë•Œ, ì´ ì§ˆë¬¸ì´ ì´ì „ ëŒ€í™” ë‚´ìš©ê³¼ ê´€ë ¨ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ° ê²½ìš°, ëŒ€í™” ë‚´ìš©ì„ ì•Œ í•„ìš” ì—†ì´ ë…ë¦½ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”. ì§ˆë¬¸ì— ë‹µí•  í•„ìš”ëŠ” ì—†ê³ , í•„ìš”í•˜ë‹¤ë©´ ê·¸ì € ë‹¤ì‹œ êµ¬ì„±í•˜ê±°ë‚˜ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”."""
        contextualize_q_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", contextualize_q_system_prompt),
                MessagesPlaceholder("chat_history"),
                ("human", "{input}"),
            ]
        )
        history_aware_retriever = create_history_aware_retriever(chat, retriever, contextualize_q_prompt)

        qa_system_prompt = """ë‹¹ì‹ ì€ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ìœ ìš©í•œ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ë‹µì„ ëª¨ë¥¸ë‹¤ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•˜ì„¸ìš”. ë‹µë³€ì€ ì„¸ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.
        {context}"""
        qa_prompt = ChatPromptTemplate.from_messages(
            [
                ("system", qa_system_prompt),
                MessagesPlaceholder("chat_history"),
                ("human", "{input}"),
            ]
        )
        Youtube_chain = create_stuff_documents_chain(chat, qa_prompt)
        self.rag_chain = create_retrieval_chain(history_aware_retriever, Youtube_chain)
        
    # RAG ë‹µë³€ ìƒì„± í•¨ìˆ˜ ì¶”ê°€
    def get_rag_answer(self, user_input, chat_history):
        if not self.rag_chain:
            return "ë¨¼ì € PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ RAG ì²´ì¸ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.", None

        result = self.rag_chain.invoke({"input": user_input, "chat_history": chat_history})
        return result["answer"], result["context"]